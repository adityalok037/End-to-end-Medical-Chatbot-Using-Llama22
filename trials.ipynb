{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okk this is all fine\n"
     ]
    }
   ],
   "source": [
    "print(\"okk this is all fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical ChatBOt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import  HuggingFaceEmbeddings \n",
    "from langchain.vectorstores import Pinecone\n",
    "from pinecone import Pinecone,ServerlessSpec\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import ctransformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcsk_78JdJ3_QpXZ7QHXr2Uv7DXJVr9GPvoYwb4akmPrL9f7AeAeBAyYu8SgxPr76JxBdukcCLz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_6jJ7po_EbXbexa5h79DrK3s8pEk5BckhnkmToYNdjSDAM3ZnkAiqY9rqD5qAhn28qk3qk4\"\n",
    "PINECONE_API_ENV =  \"us-east-1-aws\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data= load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the chunks: 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of the chunks:\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-huggingface) (0.26.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-huggingface) (0.3.21)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-huggingface) (3.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-huggingface) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-huggingface) (4.46.3)\n",
      "Requirement already satisfied: filelock in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.1.146)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: networkx in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: sniffio in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\condaa\\envs\\mchatbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-l6-v2\" )\n",
    "    return embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-l6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-l6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## test the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"kallo kalisa the don\")\n",
    "print(\"length\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11381158977746964,\n",
       " 0.03737015277147293,\n",
       " -0.05325103923678398,\n",
       " 0.0602087564766407,\n",
       " -0.10784343630075455,\n",
       " -0.007317695301026106,\n",
       " 0.10283239930868149,\n",
       " -0.07219936698675156,\n",
       " 0.07612476497888565,\n",
       " -0.015257258899509907,\n",
       " 0.04438699036836624,\n",
       " -0.06522295624017715,\n",
       " -0.031545545905828476,\n",
       " 0.05603882297873497,\n",
       " -0.00863468088209629,\n",
       " -0.018816933035850525,\n",
       " 0.02800637111067772,\n",
       " 0.03092520497739315,\n",
       " -0.008785144425928593,\n",
       " -0.03431516885757446,\n",
       " -0.05797110125422478,\n",
       " 0.03644885867834091,\n",
       " 0.04238847270607948,\n",
       " 0.04385584592819214,\n",
       " -0.08088473230600357,\n",
       " -0.05737711116671562,\n",
       " -0.015496702864766121,\n",
       " -0.009699282236397266,\n",
       " -0.01774829812347889,\n",
       " -0.09014662355184555,\n",
       " -0.05122816562652588,\n",
       " 0.021257178857922554,\n",
       " -0.04036024212837219,\n",
       " 0.02126120775938034,\n",
       " -0.0496150441467762,\n",
       " -0.041019659489393234,\n",
       " -0.05329013615846634,\n",
       " 0.131815567612648,\n",
       " 0.03461975231766701,\n",
       " -0.048066914081573486,\n",
       " 0.007686016149818897,\n",
       " -0.042599599808454514,\n",
       " -0.03554120287299156,\n",
       " 0.05099464952945709,\n",
       " -0.05610992759466171,\n",
       " -0.02027825079858303,\n",
       " -0.08037544786930084,\n",
       " -0.007684164214879274,\n",
       " 0.022366229444742203,\n",
       " -0.003900056006386876,\n",
       " -0.07948648184537888,\n",
       " -0.03631478175520897,\n",
       " -0.06088148429989815,\n",
       " -0.03789481520652771,\n",
       " 0.027694925665855408,\n",
       " -0.041385527700185776,\n",
       " 0.026375524699687958,\n",
       " 0.05177038162946701,\n",
       " 0.12053415179252625,\n",
       " 0.04638982191681862,\n",
       " 0.056395791471004486,\n",
       " -0.021249152719974518,\n",
       " -0.020561328157782555,\n",
       " 0.1068408265709877,\n",
       " -0.027972405776381493,\n",
       " -0.0910705029964447,\n",
       " -0.003960723057389259,\n",
       " 0.012339135631918907,\n",
       " -0.09847088903188705,\n",
       " 0.05124475806951523,\n",
       " 0.020017441362142563,\n",
       " -0.0642172172665596,\n",
       " 0.041930072009563446,\n",
       " -0.06304875761270523,\n",
       " 0.031152432784438133,\n",
       " 0.0234528761357069,\n",
       " -0.004036331549286842,\n",
       " -0.0028015412390232086,\n",
       " -0.0025564697571098804,\n",
       " 0.03998531028628349,\n",
       " 0.04491140693426132,\n",
       " -0.029086025431752205,\n",
       " -0.0630064383149147,\n",
       " 0.029154837131500244,\n",
       " -0.01965300366282463,\n",
       " -0.03024677000939846,\n",
       " 0.021394949406385422,\n",
       " -0.0017725222278386354,\n",
       " 0.026949211955070496,\n",
       " -0.07506512105464935,\n",
       " -0.01338932104408741,\n",
       " 0.07262719422578812,\n",
       " -0.07132311165332794,\n",
       " -0.05959034711122513,\n",
       " 0.013271342031657696,\n",
       " -0.020346641540527344,\n",
       " 0.00789862684905529,\n",
       " 0.039272721856832504,\n",
       " -0.09108304232358932,\n",
       " 0.11235546320676804,\n",
       " 0.01369334477931261,\n",
       " 0.029189052060246468,\n",
       " 0.06472723186016083,\n",
       " 0.08435079455375671,\n",
       " -0.04851013049483299,\n",
       " -0.03879709541797638,\n",
       " 0.034435417503118515,\n",
       " -0.08721506595611572,\n",
       " -0.00543163251131773,\n",
       " 0.030843952670693398,\n",
       " -0.06234171241521835,\n",
       " 0.03263016790151596,\n",
       " -0.06741775572299957,\n",
       " -0.026675792410969734,\n",
       " 0.01664040796458721,\n",
       " -0.06308120489120483,\n",
       " 0.02599075809121132,\n",
       " 0.035725854337215424,\n",
       " 0.012795047834515572,\n",
       " -0.03317305073142052,\n",
       " 0.013162534683942795,\n",
       " -0.03807656094431877,\n",
       " -0.008106580935418606,\n",
       " 0.01890954189002514,\n",
       " -0.04289235174655914,\n",
       " -0.010659534484148026,\n",
       " -0.03783348947763443,\n",
       " -1.077741893646837e-33,\n",
       " 0.043040890246629715,\n",
       " 0.006048660725355148,\n",
       " 0.031065035611391068,\n",
       " -0.04233032464981079,\n",
       " 0.06776747107505798,\n",
       " -0.09929671138525009,\n",
       " -0.07169357687234879,\n",
       " -0.09708418697118759,\n",
       " -0.10910841077566147,\n",
       " 0.024991093203425407,\n",
       " -0.04341564700007439,\n",
       " -0.08413469791412354,\n",
       " -0.04166487976908684,\n",
       " 0.016299128532409668,\n",
       " 0.10409046709537506,\n",
       " 0.1563771367073059,\n",
       " 0.006286318879574537,\n",
       " -0.019553668797016144,\n",
       " -0.02952393889427185,\n",
       " 0.006235669832676649,\n",
       " 0.06525906175374985,\n",
       " 0.07738105207681656,\n",
       " -0.016711892560124397,\n",
       " 0.018564114347100258,\n",
       " 0.041565705090761185,\n",
       " 0.027576306834816933,\n",
       " 0.02048596180975437,\n",
       " -0.05156182870268822,\n",
       " -0.09031866490840912,\n",
       " 0.04859042540192604,\n",
       " 0.03714604675769806,\n",
       " -0.020936811342835426,\n",
       " -0.0012666097609326243,\n",
       " 0.04314538463950157,\n",
       " -0.0786784365773201,\n",
       " -0.010311315767467022,\n",
       " -0.10695020109415054,\n",
       " -0.01532411016523838,\n",
       " -0.0016009551472961903,\n",
       " -0.07432074099779129,\n",
       " 0.012041469104588032,\n",
       " -0.025601103901863098,\n",
       " -0.011798136867582798,\n",
       " -0.03352015092968941,\n",
       " -0.08380138874053955,\n",
       " -0.017089130356907845,\n",
       " 0.07125682383775711,\n",
       " 0.08938714116811752,\n",
       " 0.023897936567664146,\n",
       " 0.08022411912679672,\n",
       " -0.012395592406392097,\n",
       " -0.08290019631385803,\n",
       " -0.030092556029558182,\n",
       " 0.0876668393611908,\n",
       " 0.02986878529191017,\n",
       " 0.09521548449993134,\n",
       " 0.040255919098854065,\n",
       " -0.032052770256996155,\n",
       " 0.02657432295382023,\n",
       " 0.019720975309610367,\n",
       " 0.005701216869056225,\n",
       " -0.04406806454062462,\n",
       " 0.006758134346455336,\n",
       " 0.002331652445718646,\n",
       " 0.011826221831142902,\n",
       " -0.05995381996035576,\n",
       " -0.03854793682694435,\n",
       " -0.03421281650662422,\n",
       " 0.04847671091556549,\n",
       " -0.06489390879869461,\n",
       " -0.04308213293552399,\n",
       " -0.01393743697553873,\n",
       " -0.06233443319797516,\n",
       " -0.02472553215920925,\n",
       " -0.05234985426068306,\n",
       " -0.034196000546216965,\n",
       " 0.08363068848848343,\n",
       " 0.01929265633225441,\n",
       " -0.053240980952978134,\n",
       " 0.059424009174108505,\n",
       " 0.07788250595331192,\n",
       " 0.022407324984669685,\n",
       " 0.06649666279554367,\n",
       " -0.008263681083917618,\n",
       " 0.07225927710533142,\n",
       " -0.0021402707789093256,\n",
       " 0.01506131049245596,\n",
       " -0.0028566201217472553,\n",
       " -0.02298031374812126,\n",
       " 0.033841222524642944,\n",
       " -0.0790814757347107,\n",
       " -0.01163864228874445,\n",
       " -0.017588241025805473,\n",
       " -0.05440916866064072,\n",
       " -0.002075579948723316,\n",
       " 6.514354593386953e-34,\n",
       " 0.0940965786576271,\n",
       " 0.010795540176331997,\n",
       " 0.14944909512996674,\n",
       " 0.06704213470220566,\n",
       " 0.07014358043670654,\n",
       " -0.06969844549894333,\n",
       " 0.03335736691951752,\n",
       " 0.04487483203411102,\n",
       " 0.07469285279512405,\n",
       " -0.03371128812432289,\n",
       " 0.03297499194741249,\n",
       " -0.045908112078905106,\n",
       " 0.0392824150621891,\n",
       " -0.0074621872045099735,\n",
       " 0.07924765348434448,\n",
       " 0.04370380938053131,\n",
       " 0.07479394972324371,\n",
       " 0.009962883777916431,\n",
       " -0.014729674905538559,\n",
       " -0.0007316324044950306,\n",
       " -0.053283896297216415,\n",
       " 0.03932451829314232,\n",
       " -0.0433044508099556,\n",
       " -0.05193406343460083,\n",
       " -0.05912361666560173,\n",
       " -0.018783245235681534,\n",
       " 0.022983944043517113,\n",
       " 0.06554512679576874,\n",
       " -0.10565290600061417,\n",
       " 0.06241244822740555,\n",
       " 0.002836544532328844,\n",
       " -0.06539801508188248,\n",
       " -0.016350440680980682,\n",
       " 0.018611731007695198,\n",
       " -0.01775379665195942,\n",
       " -0.011874068528413773,\n",
       " -0.0036773099564015865,\n",
       " 0.053803715854883194,\n",
       " 0.003109666984528303,\n",
       " 0.03757570683956146,\n",
       " 0.04098295792937279,\n",
       " 0.06849521398544312,\n",
       " -0.01306547224521637,\n",
       " 0.058884620666503906,\n",
       " -0.015918979421257973,\n",
       " -0.028705324977636337,\n",
       " 0.01526107918471098,\n",
       " 0.09678991883993149,\n",
       " 0.023544279858469963,\n",
       " -0.0808815136551857,\n",
       " 0.054781317710876465,\n",
       " 0.027903331443667412,\n",
       " -0.027680525556206703,\n",
       " 0.04259003698825836,\n",
       " 0.057625431567430496,\n",
       " 0.011684505268931389,\n",
       " 0.06846164166927338,\n",
       " 0.021930932998657227,\n",
       " -0.0555124394595623,\n",
       " -0.018438465893268585,\n",
       " 0.026948997750878334,\n",
       " -0.05536758899688721,\n",
       " -0.013403511606156826,\n",
       " -0.03431742638349533,\n",
       " 0.017607184126973152,\n",
       " 0.02404998615384102,\n",
       " -0.03347766026854515,\n",
       " 0.06244176998734474,\n",
       " -0.05139463022351265,\n",
       " -0.005292116664350033,\n",
       " -0.03947944939136505,\n",
       " -0.026742171496152878,\n",
       " -0.12147289514541626,\n",
       " -0.06717856973409653,\n",
       " 0.002380835823714733,\n",
       " 0.015399936586618423,\n",
       " -0.13252349197864532,\n",
       " 0.1145177036523819,\n",
       " 0.09124305099248886,\n",
       " 0.04037529602646828,\n",
       " 0.03791194409132004,\n",
       " -0.009716806001961231,\n",
       " -0.08550184220075607,\n",
       " 0.003993079997599125,\n",
       " 0.11641792953014374,\n",
       " 0.06775270402431488,\n",
       " -0.007948447950184345,\n",
       " -0.030299251899123192,\n",
       " 0.09329281747341156,\n",
       " -0.020957201719284058,\n",
       " -0.032457757741212845,\n",
       " 0.055902671068906784,\n",
       " 0.09474404901266098,\n",
       " 0.025170374661684036,\n",
       " -0.007729684002697468,\n",
       " -1.4765244138459366e-08,\n",
       " 0.050694212317466736,\n",
       " 0.05777040868997574,\n",
       " -0.0024610920809209347,\n",
       " 0.0025273740757256746,\n",
       " 0.008150787092745304,\n",
       " -0.019411543384194374,\n",
       " -0.016967391595244408,\n",
       " -0.04304226115345955,\n",
       " 0.018862996250391006,\n",
       " 0.05894548073410988,\n",
       " -0.044511180371046066,\n",
       " 0.02298823371529579,\n",
       " 0.0252582598477602,\n",
       " -0.003110339865088463,\n",
       " -0.0002668044762685895,\n",
       " 0.04303721711039543,\n",
       " -0.055099572986364365,\n",
       " 0.005616466514766216,\n",
       " 0.010500488802790642,\n",
       " -0.0575084462761879,\n",
       " 0.07520443201065063,\n",
       " 0.025365181267261505,\n",
       " 0.04249371960759163,\n",
       " -0.03191952034831047,\n",
       " 0.010716383345425129,\n",
       " 0.04014403745532036,\n",
       " 0.01941673643887043,\n",
       " -0.021113667637109756,\n",
       " 0.044350266456604004,\n",
       " 0.03443954139947891,\n",
       " 0.03644261136651039,\n",
       " 0.020105386152863503,\n",
       " -0.029418062418699265,\n",
       " -0.08560370653867722,\n",
       " -0.017615685239434242,\n",
       " 0.002456618007272482,\n",
       " -0.016552044078707695,\n",
       " 0.006335644517093897,\n",
       " 0.005033351015299559,\n",
       " 0.0303496066480875,\n",
       " -0.014807994477450848,\n",
       " 0.0002551455982029438,\n",
       " -0.00023157603573054075,\n",
       " 0.01956816390156746,\n",
       " -0.09797628968954086,\n",
       " 0.1062648743391037,\n",
       " -0.0017619390273466706,\n",
       " 0.005138014908879995,\n",
       " -0.06129509583115578,\n",
       " -0.018847022205591202,\n",
       " -0.055238332599401474,\n",
       " 0.04792894423007965,\n",
       " -0.010200622491538525,\n",
       " 0.08241715282201767,\n",
       " 0.03590387478470802,\n",
       " -0.013531995005905628,\n",
       " 0.09457501769065857,\n",
       " 0.023645712062716484,\n",
       " -0.00425390200689435,\n",
       " 0.021720044314861298,\n",
       " 0.04783802479505539,\n",
       " -0.045973040163517,\n",
       " 0.000300609041005373,\n",
       " -0.007943236269056797]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pinecone library\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundException",
     "evalue": "(404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Date': 'Fri, 29 Nov 2024 05:47:26 GMT', 'Content-Length': '0', 'Connection': 'keep-alive', 'server': 'envoy'})\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedical-chatbot\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Check if index already exists, if not create it\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpinecone_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnames:\n\u001b[0;32m     20\u001b[0m     pinecone_client\u001b[38;5;241m.\u001b[39mcreate_index(\n\u001b[0;32m     21\u001b[0m         name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[0;32m     22\u001b[0m         dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m384\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m         )\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Assuming text_chunks and embeddings are already defined\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Creating embeddings for each of the text chunks & storing\u001b[39;00m\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\control\\pinecone.py:506\u001b[0m, in \u001b[0;36mlist_indexes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    499\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Describes a Pinecone index.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    :param name: the name of the index to describe.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m    :return: Returns an `IndexModel` object\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m    which gives access to properties such as the\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    index name, dimension, metric, host url, status,\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m    and spec.\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m \n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    ### Getting your index host url\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m    In a real production situation, you probably want to\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m    store the host url in an environment variable so you\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    don't have to call describe_index and re-fetch it\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m    every time you want to use the index. But this example\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m    shows how to get the value from the API using describe_index.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    ```python\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    from pinecone import Pinecone, Index\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    client = Pinecone()\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    description = client.describe_index(\"my_index\")\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    host = description.host\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    print(f\"Your index is hosted at {description.host}\")\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    index = client.Index(name=\"my_index\", host=host)\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m    index.upsert(vectors=[...])\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    529\u001b[0m     api_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_api\n\u001b[0;32m    530\u001b[0m     description \u001b[38;5;241m=\u001b[39m api_instance\u001b[38;5;241m.\u001b[39mdescribe_index(name)\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:761\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\control\\api\\manage_indexes_api.py:792\u001b[0m, in \u001b[0;36mManageIndexesApi.__init__.<locals>.__list_indexes\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_check_return_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_check_return_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    791\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:819\u001b[0m, in \u001b[0;36mcall_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    811\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[0;32m    814\u001b[0m \u001b[38;5;124;03m    api_instance = InferenceApi()\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m    api_instance.embed  # this is an instance of the class Endpoint\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;124;03m    api_instance.embed()  # this invokes api_instance.embed.__call__()\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;124;03m    which then invokes the callable functions stored in that endpoint at\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m    api_instance.embed.callable or self.callable in this class\u001b[39;00m\n\u001b[1;32m--> 819\u001b[0m \n\u001b[0;32m    820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:380\u001b[0m, in \u001b[0;36mcall_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_api\u001b[39m(\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    337\u001b[0m     resource_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m     _check_type: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m ):\n\u001b[0;32m    356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    To make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    :param resource_path: Path to method endpoint.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    :param method: Method to call.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    :param path_params: Path parameters in the url.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    :param query_params: Query parameters in the url.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    :param header_params: Header parameters to be\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m        placed in the request header.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    :param body: Request body.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    :param post_params dict: Request post form parameters,\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m        for `application/x-www-form-urlencoded`, `multipart/form-data`.\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    :param auth_settings list: Auth Settings names for the request.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    :param response_type: For the response, a tuple containing:\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m        valid classes\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m        a list containing valid classes (for list schemas)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m        a dict containing a tuple of valid classes as the value\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        Example values:\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m        (str,)\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m        (Pet,)\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m        (float, none_type)\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m        ([int, none_type],)\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m        ({str: (bool, str, int, float, date, datetime, str, none_type)},)\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m \u001b[38;5;124;03m    :param files: key -> field name, value -> a list of open file\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m        objects for `multipart/form-data`.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m    :type files: dict\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    :param async_req bool: execute request asynchronously\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m    :type async_req: bool, optional\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    :param _return_http_data_only: response data without head status code\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m                                   and headers\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    :type _return_http_data_only: bool, optional\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    :param collection_formats: dict of collection formats for path, query,\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m        header, and post parameters.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    :type collection_formats: dict, optional\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    :param _preload_content: if False, the urllib3.HTTPResponse object will\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m                             be returned without reading/decoding response\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m                             data. Default is True.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    :type _preload_content: bool, optional\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    :param _request_timeout: timeout setting for this request. If one\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m                             number provided, it will be total request\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m                             timeout. It can also be a pair (tuple) of\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m                             (connection, read) timeouts.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    :param _check_type: boolean describing if the data back from the server\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m        should have its type checked.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    :type _check_type: bool, optional\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m        If async_req parameter is True,\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m        the request will be called asynchronously.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m        The method will return the request thread.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m        If parameter async_req is False or missing,\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m        then the method will return the response directly.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m async_threadpool_executor:\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[0;32m    412\u001b[0m             resource_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m             _check_type,\n\u001b[0;32m    428\u001b[0m         )\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:187\u001b[0m, in \u001b[0;36m__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:175\u001b[0m, in \u001b[0;36m__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m         resource_path \u001b[38;5;241m=\u001b[39m resource_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m k, quote(\u001b[38;5;28mstr\u001b[39m(v), safe\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39msafe_chars_for_path_param))\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# query parameters\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_params:\n\u001b[0;32m    176\u001b[0m     query_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msanitize_for_serialization(query_params)\n\u001b[0;32m    177\u001b[0m     query_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters_to_tuples(query_params, collection_formats)\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\api_client.py:434\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[0;32m    412\u001b[0m         resource_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m         _check_type,\n\u001b[0;32m    428\u001b[0m     )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api(\n\u001b[0;32m    432\u001b[0m         resource_path,\n\u001b[0;32m    433\u001b[0m         method,\n\u001b[1;32m--> 434\u001b[0m         path_params,\n\u001b[0;32m    435\u001b[0m         query_params,\n\u001b[0;32m    436\u001b[0m         header_params,\n\u001b[0;32m    437\u001b[0m         body,\n\u001b[0;32m    438\u001b[0m         post_params,\n\u001b[0;32m    439\u001b[0m         files,\n\u001b[0;32m    440\u001b[0m         response_type,\n\u001b[0;32m    441\u001b[0m         auth_settings,\n\u001b[0;32m    442\u001b[0m         _return_http_data_only,\n\u001b[0;32m    443\u001b[0m         collection_formats,\n\u001b[0;32m    444\u001b[0m         _preload_content,\n\u001b[0;32m    445\u001b[0m         _request_timeout,\n\u001b[0;32m    446\u001b[0m         _host,\n\u001b[0;32m    447\u001b[0m         _check_type,\n\u001b[0;32m    448\u001b[0m     )\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[0;32m    451\u001b[0m     retry_api_call,\n\u001b[0;32m    452\u001b[0m     args\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    476\u001b[0m     )\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\rest.py:284\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[1;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGET\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\condaa\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\core\\openapi\\shared\\rest.py:274\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n",
      "\u001b[1;31mNotFoundException\u001b[0m: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Date': 'Fri, 29 Nov 2024 05:47:26 GMT', 'Content-Length': '0', 'Connection': 'keep-alive', 'server': 'envoy'})\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone as VectorStorePinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "PINECONE_API_KEY=\"pcsk_6jJ7po_EbXbexa5h79DrK3s8pEk5BckhnkmToYNdjSDAM3ZnkAiqY9rqD5qAhn28qk3qk4\"\n",
    "# Set environment variables\n",
    "PINECONE_HOST = \"https://medical-chatbot-8zgpp1i.svc.aped-4627-b74a.pinecone.io\"\n",
    "\n",
    "pinecone.init(PINECONE_API_KEY,\n",
    "               environment=PINECONE_)\n",
    "\n",
    "index_name='medical-chatbot'\n",
    "#creating embeddings for each of the text chunks & storing\n",
    "dosearch=Pinecone.from_texts([t.page_content for t in text_chunks],embeddings,index_name=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Replace with your actual Pinecone API key\n",
    "api_key = \"pcsk_7WqJb4_7Vj1Ut8iW4KpyhZDroqsBhtnfFpHpBFULEv135DevgAheceXu25qCRKymf9NjN9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_7WqJb4_7Vj1Ut8iW4KpyhZDroqsBhtnfFpHpBFULEv135DevgAheceXu25qCRKymf9NjN9\")\n",
    "\n",
    "pc.create_index(\n",
    "  name=\"medi-chatbot\",\n",
    "  dimension=384,\n",
    "  metric=\"cosine\",\n",
    "  spec=ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-east-1\"\n",
    "  ),\n",
    "  deletion_protection=\"disabled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 0}},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Check index stats\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m vector_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Use embed_documents() for a batch of text\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Extract the first result\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     vector_data\u001b[38;5;241m.\u001b[39mappend((chunk\u001b[38;5;241m.\u001b[39mid, embedding, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_value\u001b[39m\u001b[38;5;124m\"\u001b[39m}))  \u001b[38;5;66;03m# Include metadata if needed\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Initialize the embeddings model\n",
    "# embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "# Generate embeddings for each text chunk\n",
    "vector_data = []\n",
    "for chunk in text_chunks:\n",
    "    # Use embed_documents() for a batch of text\n",
    "    embedding = embeddings.embed_documents([chunk.page_content])[0]  # Extract the first result\n",
    "    vector_data.append((chunk.id, embedding, {\"metadata_key\": \"metadata_value\"}))  # Include metadata if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
